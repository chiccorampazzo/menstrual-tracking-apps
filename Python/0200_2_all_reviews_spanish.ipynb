{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0301"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Standard Directory is:  C:\\Users\\rbarker\\OneDrive\\02_Fertapp\\01_Python_script\n",
      "New working directory is:  C:\\Users\\rbarker\\OneDrive\\02_Fertapp\n"
     ]
    }
   ],
   "source": [
    "import contextualized_topic_models\n",
    "from contextualized_topic_models.models.ctm import ZeroShotTM, CombinedTM\n",
    "from contextualized_topic_models.utils.data_preparation import TopicModelDataPreparation\n",
    "from contextualized_topic_models.utils.preprocessing import WhiteSpacePreprocessingStopwords\n",
    "import nltk\n",
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd    \n",
    "import os\n",
    "import pickle\n",
    "cwd = os.getcwd()\n",
    "print('Current Standard Directory is: ', cwd)\n",
    "absolute_path = 'C:/Users/rbarker/OneDrive/02_Fertapp' # for work PC\n",
    "os.chdir(absolute_path)\n",
    "print('New working directory is: ', os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### import my file of cleaned, multilingual data from R script\n",
    "filename = '03_data/02_output/0100_reliable_langdetection.csv' # load dataset of reviews \n",
    "fullsample = pd.read_csv(filename, usecols = [\"app\", \"review\", \"language\", \"date\", \"rating\"], header='infer', encoding=\"utf-8\") \n",
    "fullsample.columns = ['id', 'text', 'language', 'date', 'rating'] # rename columns \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "spanishsample = fullsample[fullsample['language'] == \"Spanish\"]\n",
    "nonspanishsample = fullsample[fullsample['language'] != \"Spanish\"] # selecting all non-spanish texts from the earlier sample\n",
    "test_docs = nonspanishsample['text'].tolist() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_seeds():\n",
    "  torch.manual_seed(10)\n",
    "  torch.cuda.manual_seed(10)\n",
    "  np.random.seed(10)\n",
    "  random.seed(10)\n",
    "  torch.backends.cudnn.enabled = False\n",
    "  torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\rbarker\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "### Preprocessing\n",
    "from nltk.corpus import stopwords as stop_words\n",
    "nltk.download('stopwords')\n",
    "stopwords = list(set(stop_words.words('spanish')))\n",
    "\n",
    "# from 10_fertapp_cotis_python\n",
    "new_stopwords = [\"im\", \"x\", \"xx\", \"xxx\", \"xxxx\", \"xo\", \"xoxo\", \"xox\", \"day\",\n",
    "                 \"ovia\", \"ladytimer\", \"clue\", \"pinkbird\", \"clue\", \"Ovia\",\n",
    "                 \"clover\", \"womanlog\", \"fertility friend\", \"woom\",\n",
    "                 \"tempdrop\", \"femm\", \"glow\", \"maya\", \"natural cycles\", \"ava\",\n",
    "                 \"kindara\", \"flo\", # these from fertility apps\n",
    "                 \"app\", \"apps\", \"application\", \"applications\", \"nurx\"]\n",
    "\n",
    "stopwords = list(set(stopwords+new_stopwords)) # combine the two lists, the base and the custom stop words\n",
    "\n",
    "documents = spanishsample.text.tolist()\n",
    "sp = WhiteSpacePreprocessingStopwords(documents, stopwords_list=stopwords, min_words=3, remove_numbers=True,\n",
    "                             max_df=0.4) \n",
    "preprocessed_documents, unpreprocessed_corpus, vocab = sp.preprocess()\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import pickle\n",
    "df_unpreprocessed_corpus = pd.DataFrame(unpreprocessed_corpus)\n",
    "df_spanishsample = pd.DataFrame(spanishsample)\n",
    "df_unpreprocessed_corpus.columns = ['text']\n",
    "\n",
    "keys = list(df_unpreprocessed_corpus.columns.values)\n",
    "i1 = df_spanishsample.set_index(keys).index\n",
    "i2 = df_unpreprocessed_corpus.set_index(keys).index\n",
    "toremove = df_spanishsample[~i1.isin(i2)]\n",
    "toremove = list(toremove['text'])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "scriptfile = '0300_'\n",
    "folder = '03_data/02_output/01_spanish/'\n",
    "language = \"spanish_\"\n",
    "spanishsample = spanishsample[-spanishsample[\"text\"].isin(toremove)]\n",
    "spanishsample.to_csv(folder  + scriptfile + language + \"df_spanishsample.csv\",index=False)\n",
    "pickle.dump(spanishsample, open(folder + scriptfile + \"spanishsample.pkl\", \"wb\"))\n",
    "pickle.dump(nonspanishsample, open(folder + scriptfile + \"nonspanishsample.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc467bfae8114ece9577bcfa90c98077",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/263 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "['aborto',\n",
       " 'abre',\n",
       " 'abri',\n",
       " 'abrir',\n",
       " 'abrirla',\n",
       " 'abro',\n",
       " 'absolutamente',\n",
       " 'aca',\n",
       " 'acaba',\n",
       " 'acabo',\n",
       " 'acceder',\n",
       " 'accesible',\n",
       " 'acceso',\n",
       " 'accidente',\n",
       " 'accidentes',\n",
       " 'acerca',\n",
       " 'acertada',\n",
       " 'acertadas',\n",
       " 'acertado',\n",
       " 'acertados',\n",
       " 'acertar',\n",
       " 'acertiva',\n",
       " 'acerto',\n",
       " 'acierta',\n",
       " 'acne',\n",
       " 'acompana',\n",
       " 'aconseja',\n",
       " 'aconsejo',\n",
       " 'activadas',\n",
       " 'activar',\n",
       " 'actividad',\n",
       " 'actividades',\n",
       " 'actual',\n",
       " 'actualice',\n",
       " 'actualiza',\n",
       " 'actualizacion',\n",
       " 'actualizaciones',\n",
       " 'actualizada',\n",
       " 'actualizado',\n",
       " 'actualizando',\n",
       " 'actualizar',\n",
       " 'actualizarla',\n",
       " 'actualizaron',\n",
       " 'actualizo',\n",
       " 'actualmente',\n",
       " 'acuerdo',\n",
       " 'adapta',\n",
       " 'adecuado',\n",
       " 'adelanta',\n",
       " 'adelante',\n",
       " 'ademas',\n",
       " 'adicional',\n",
       " 'adicionales',\n",
       " 'adolescentes',\n",
       " 'adoro',\n",
       " 'afecta',\n",
       " 'agenda',\n",
       " 'agrada',\n",
       " 'agradable',\n",
       " 'agradeceria',\n",
       " 'agradecida',\n",
       " 'agradezco',\n",
       " 'agrado',\n",
       " 'agregar',\n",
       " 'agregaran',\n",
       " 'agregaria',\n",
       " 'agregarle',\n",
       " 'agreguen',\n",
       " 'agua',\n",
       " 'ah',\n",
       " 'ahi',\n",
       " 'ahora',\n",
       " 'ahorita',\n",
       " 'ajusta',\n",
       " 'ajustar',\n",
       " 'ajustes',\n",
       " 'ala',\n",
       " 'alarma',\n",
       " 'alarmas',\n",
       " 'alerta',\n",
       " 'alertas',\n",
       " 'alguien',\n",
       " 'algun',\n",
       " 'alguna',\n",
       " 'alguno',\n",
       " 'alimentacion',\n",
       " 'alla',\n",
       " 'alli',\n",
       " 'alrededor',\n",
       " 'alta',\n",
       " 'altamente',\n",
       " 'alto',\n",
       " 'amaba',\n",
       " 'ambas',\n",
       " 'ame',\n",
       " 'ami',\n",
       " 'amiga',\n",
       " 'amigable',\n",
       " 'amigas',\n",
       " 'amo',\n",
       " 'amor',\n",
       " 'amplia',\n",
       " 'ampliamente',\n",
       " 'anadieran',\n",
       " 'anadir',\n",
       " 'anadiria',\n",
       " 'analisis',\n",
       " 'analiza',\n",
       " 'analizar',\n",
       " 'and',\n",
       " 'anda',\n",
       " 'andaba',\n",
       " 'andar',\n",
       " 'ando',\n",
       " 'andres',\n",
       " 'android',\n",
       " 'anillo',\n",
       " 'animo',\n",
       " 'animos',\n",
       " 'ano',\n",
       " 'anos',\n",
       " 'anotaciones',\n",
       " 'anotado',\n",
       " 'anotando',\n",
       " 'anotar',\n",
       " 'anterior',\n",
       " 'anteriores',\n",
       " 'anteriormente',\n",
       " 'anticipacion',\n",
       " 'anticonceptiva',\n",
       " 'anticonceptivas',\n",
       " 'anticonceptivo',\n",
       " 'anticonceptivos',\n",
       " 'antigua',\n",
       " 'antojos',\n",
       " 'anual',\n",
       " 'anuncio',\n",
       " 'anuncios',\n",
       " 'ap',\n",
       " 'aparece',\n",
       " 'aparecen',\n",
       " 'aparecer',\n",
       " 'aparecia',\n",
       " 'aparecio',\n",
       " 'apariencia',\n",
       " 'apartado',\n",
       " 'aparte',\n",
       " 'apenas',\n",
       " 'apesar',\n",
       " 'aplicacion',\n",
       " 'aplicaciones',\n",
       " 'aplicasion',\n",
       " 'aporta',\n",
       " 'apoyo',\n",
       " 'apple',\n",
       " 'aprende',\n",
       " 'aprender',\n",
       " 'aprendes',\n",
       " 'aprendi',\n",
       " 'aprendido',\n",
       " 'aprendiendo',\n",
       " 'aprendo',\n",
       " 'aprox',\n",
       " 'aproxima',\n",
       " 'aproximadamente',\n",
       " 'aproximado',\n",
       " 'apuntar',\n",
       " 'apunto',\n",
       " 'aquellas',\n",
       " 'aqui',\n",
       " 'arreglan',\n",
       " 'arreglar',\n",
       " 'arreglarlo',\n",
       " 'arreglen',\n",
       " 'arreglenlo',\n",
       " 'arrepiento',\n",
       " 'articulos',\n",
       " 'asco',\n",
       " 'asertiva',\n",
       " 'asi',\n",
       " 'asistente',\n",
       " 'aspecto',\n",
       " 'aspectos',\n",
       " 'asta',\n",
       " 'atencion',\n",
       " 'atenta',\n",
       " 'atina',\n",
       " 'atinada',\n",
       " 'atractiva',\n",
       " 'atras',\n",
       " 'atrasa',\n",
       " 'atraso',\n",
       " 'aun',\n",
       " 'aunq',\n",
       " 'aunque',\n",
       " 'automaticamente',\n",
       " 'automatico',\n",
       " 'aveces',\n",
       " 'avisa',\n",
       " 'avisar',\n",
       " 'avise',\n",
       " 'aviso',\n",
       " 'avisos',\n",
       " 'ay',\n",
       " 'ayer',\n",
       " 'ayuda',\n",
       " 'ayudaba',\n",
       " 'ayudado',\n",
       " 'ayudan',\n",
       " 'ayudando',\n",
       " 'ayudar',\n",
       " 'ayudara',\n",
       " 'ayudaria',\n",
       " 'ayudarme',\n",
       " 'ayudarnos',\n",
       " 'ayudaron',\n",
       " 'ayudarte',\n",
       " 'ayude',\n",
       " 'ayuden',\n",
       " 'ayudenme',\n",
       " 'ayudo',\n",
       " 'azul',\n",
       " 'backup',\n",
       " 'baja',\n",
       " 'bajado',\n",
       " 'bajar',\n",
       " 'bajara',\n",
       " 'baje',\n",
       " 'bajo',\n",
       " 'basal',\n",
       " 'base',\n",
       " 'basica',\n",
       " 'basicas',\n",
       " 'basico',\n",
       " 'bastante',\n",
       " 'bastantes',\n",
       " 'bateria',\n",
       " 'bb',\n",
       " 'bebe',\n",
       " 'beber',\n",
       " 'bebes',\n",
       " 'beneficios',\n",
       " 'bien',\n",
       " 'bienestar',\n",
       " 'blanco',\n",
       " 'bloquea',\n",
       " 'bloqueado',\n",
       " 'bn',\n",
       " 'bonita',\n",
       " 'bonito',\n",
       " 'bonitos',\n",
       " 'borra',\n",
       " 'borrado',\n",
       " 'borran',\n",
       " 'borrar',\n",
       " 'borrarla',\n",
       " 'borraron',\n",
       " 'borre',\n",
       " 'borro',\n",
       " 'boton',\n",
       " 'brinda',\n",
       " 'brindan',\n",
       " 'buen',\n",
       " 'buena',\n",
       " 'buenas',\n",
       " 'buenisima',\n",
       " 'buenisimo',\n",
       " 'buenisimos',\n",
       " 'bueno',\n",
       " 'buenos',\n",
       " 'busca',\n",
       " 'buscaba',\n",
       " 'buscan',\n",
       " 'buscando',\n",
       " 'buscar',\n",
       " 'buscare',\n",
       " 'buscas',\n",
       " 'busco',\n",
       " 'busque',\n",
       " 'busqueda',\n",
       " 'cabeza',\n",
       " 'cada',\n",
       " 'cae',\n",
       " 'calcula',\n",
       " 'calcular',\n",
       " 'calculo',\n",
       " 'calculos',\n",
       " 'calendario',\n",
       " 'calendarios',\n",
       " 'calidad',\n",
       " 'calificacion',\n",
       " 'cambia',\n",
       " 'cambiado',\n",
       " 'cambian',\n",
       " 'cambiando',\n",
       " 'cambiar',\n",
       " 'cambiaria',\n",
       " 'cambiarla',\n",
       " 'cambiarlo',\n",
       " 'cambiarme',\n",
       " 'cambiaron',\n",
       " 'cambias',\n",
       " 'cambie',\n",
       " 'cambien',\n",
       " 'cambies',\n",
       " 'cambio',\n",
       " 'cambios',\n",
       " 'camino',\n",
       " 'cancelar',\n",
       " 'cantidad',\n",
       " 'capaz',\n",
       " 'cara',\n",
       " 'caracteristicas',\n",
       " 'carga',\n",
       " 'cargando',\n",
       " 'cargar',\n",
       " 'casa',\n",
       " 'casi',\n",
       " 'caso',\n",
       " 'casos',\n",
       " 'categoria',\n",
       " 'causa',\n",
       " 'cel',\n",
       " 'celu',\n",
       " 'celular',\n",
       " 'celulares',\n",
       " 'cerca',\n",
       " 'cero',\n",
       " 'cerrar',\n",
       " 'cerro',\n",
       " 'certera',\n",
       " 'certeras',\n",
       " 'certero',\n",
       " 'chat',\n",
       " 'checar',\n",
       " 'chevere',\n",
       " 'chica',\n",
       " 'chicas',\n",
       " 'ciclo',\n",
       " 'ciclos',\n",
       " 'cien',\n",
       " 'ciento',\n",
       " 'cierra',\n",
       " 'cierta',\n",
       " 'ciertas',\n",
       " 'cierto',\n",
       " 'ciertos',\n",
       " 'cinco',\n",
       " 'citas',\n",
       " 'clara',\n",
       " 'claramente',\n",
       " 'claro',\n",
       " 'clave',\n",
       " 'cobran',\n",
       " 'cobrar',\n",
       " 'cobro',\n",
       " 'codigo',\n",
       " 'codigos',\n",
       " 'coincide',\n",
       " 'coinciden',\n",
       " 'colicos',\n",
       " 'colocar',\n",
       " 'color',\n",
       " 'colores',\n",
       " 'comence',\n",
       " 'comentario',\n",
       " 'comentarios',\n",
       " 'comenzar',\n",
       " 'comenzo',\n",
       " 'comerciales',\n",
       " 'comienza',\n",
       " 'comienzo',\n",
       " 'comoda',\n",
       " 'comodo',\n",
       " 'comparacion',\n",
       " 'comparar',\n",
       " 'compartir',\n",
       " 'compatible',\n",
       " 'completa',\n",
       " 'completamente',\n",
       " 'completar',\n",
       " 'completas',\n",
       " 'completo',\n",
       " 'completos',\n",
       " 'complicaciones',\n",
       " 'complicada',\n",
       " 'complicado',\n",
       " 'comportamiento',\n",
       " 'compra',\n",
       " 'comprar',\n",
       " 'comprarla',\n",
       " 'compre',\n",
       " 'comprender',\n",
       " 'comun',\n",
       " 'comunidad',\n",
       " 'concebir',\n",
       " 'concejos',\n",
       " 'concepcion',\n",
       " 'conexion',\n",
       " 'confiable',\n",
       " 'confianza',\n",
       " 'confiar',\n",
       " 'configuracion',\n",
       " 'configurar',\n",
       " 'confio',\n",
       " 'conforme',\n",
       " 'congelada',\n",
       " 'conmigo',\n",
       " 'conoce',\n",
       " 'conocer',\n",
       " 'conocerme',\n",
       " 'conocerte',\n",
       " 'conoces',\n",
       " 'conoci',\n",
       " 'conocido',\n",
       " 'conocimiento',\n",
       " 'conozco',\n",
       " 'consciente',\n",
       " 'consegui',\n",
       " 'conseguido',\n",
       " 'conseguir',\n",
       " 'consejo',\n",
       " 'consejos',\n",
       " 'considero',\n",
       " 'consigo',\n",
       " 'constante',\n",
       " 'constantemente',\n",
       " 'consulta',\n",
       " 'consultar',\n",
       " 'consultas',\n",
       " 'contacto',\n",
       " 'contando',\n",
       " 'contar',\n",
       " 'contenido',\n",
       " 'contenidos',\n",
       " 'contenta',\n",
       " 'conteo',\n",
       " 'contiene',\n",
       " 'continuar',\n",
       " 'contrario',\n",
       " 'contrasena',\n",
       " 'control',\n",
       " 'controla',\n",
       " 'controlada',\n",
       " 'controlado',\n",
       " 'controlados',\n",
       " 'controlando',\n",
       " 'controlar',\n",
       " 'controles',\n",
       " 'controlo',\n",
       " 'cool',\n",
       " 'copa',\n",
       " 'copia',\n",
       " 'copias',\n",
       " 'corazon',\n",
       " 'correcta',\n",
       " 'correctamente',\n",
       " 'correctas',\n",
       " 'correcto',\n",
       " 'correctos',\n",
       " 'corregir',\n",
       " 'correo',\n",
       " 'correos',\n",
       " 'cosa',\n",
       " 'cosas',\n",
       " 'cositas',\n",
       " 'costo',\n",
       " 'creadores',\n",
       " 'crear',\n",
       " 'crecimiento',\n",
       " 'credito',\n",
       " 'creditos',\n",
       " 'crei',\n",
       " 'creo',\n",
       " 'cuales',\n",
       " 'cualquier',\n",
       " 'cualquiera',\n",
       " 'cuanta',\n",
       " 'cuantas',\n",
       " 'cuanto',\n",
       " 'cuantos',\n",
       " 'cuatro',\n",
       " 'cuenta',\n",
       " 'cuentas',\n",
       " 'cuento',\n",
       " 'cuerpo',\n",
       " 'cuesta',\n",
       " 'cuestion',\n",
       " 'cuestionarios',\n",
       " 'cuestiones',\n",
       " 'cuidado',\n",
       " 'cuidados',\n",
       " 'cuidar',\n",
       " 'cuidarme',\n",
       " 'cuidarte',\n",
       " 'cumple',\n",
       " 'cursos',\n",
       " 'cute',\n",
       " 'da',\n",
       " 'daba',\n",
       " 'daban',\n",
       " 'dado',\n",
       " 'dan',\n",
       " 'dando',\n",
       " 'dar',\n",
       " 'dare',\n",
       " 'daria',\n",
       " 'darle',\n",
       " 'darme',\n",
       " 'darte',\n",
       " 'das',\n",
       " 'dato',\n",
       " 'datos',\n",
       " 'debe',\n",
       " 'debemos',\n",
       " 'deben',\n",
       " 'deberia',\n",
       " 'deberiamos',\n",
       " 'deberian',\n",
       " 'debes',\n",
       " 'debia',\n",
       " 'debido',\n",
       " 'debo',\n",
       " 'decepcion',\n",
       " 'decepcionada',\n",
       " 'decia',\n",
       " 'decidi',\n",
       " 'decir',\n",
       " 'defecto',\n",
       " 'definitivamente',\n",
       " 'deja',\n",
       " 'dejaba',\n",
       " 'dejado',\n",
       " 'dejan',\n",
       " 'dejar',\n",
       " 'deje',\n",
       " 'dejen',\n",
       " 'dejo',\n",
       " 'demaciado',\n",
       " 'demas',\n",
       " 'demasiada',\n",
       " 'demasiado',\n",
       " 'den',\n",
       " 'dentro',\n",
       " 'depende',\n",
       " 'dependiendo',\n",
       " 'des',\n",
       " 'desarrolladores',\n",
       " 'desarrollo',\n",
       " 'desastre',\n",
       " 'descanso',\n",
       " 'descarga',\n",
       " 'descargado',\n",
       " 'descargar',\n",
       " 'descargarla',\n",
       " 'descarge',\n",
       " 'descargo',\n",
       " 'descargue',\n",
       " 'descarguen',\n",
       " 'descarguenla',\n",
       " 'describir',\n",
       " 'descripcion',\n",
       " 'descubri',\n",
       " 'descubrir',\n",
       " 'deseado',\n",
       " 'deseas',\n",
       " 'deseo',\n",
       " 'desinstalado',\n",
       " 'desinstalar',\n",
       " 'desinstalarla',\n",
       " 'desinstale',\n",
       " 'desinstalo',\n",
       " 'despistada',\n",
       " 'despistadas',\n",
       " 'desprevenida',\n",
       " 'despues',\n",
       " 'detallada',\n",
       " 'detallado',\n",
       " 'detalle',\n",
       " 'detalles',\n",
       " 'detectar',\n",
       " 'detuvo',\n",
       " 'di',\n",
       " 'dia',\n",
       " 'diaria',\n",
       " 'diariamente',\n",
       " 'diarias',\n",
       " 'diario',\n",
       " 'diarios',\n",
       " 'dias',\n",
       " 'dice',\n",
       " 'dicen',\n",
       " 'dicho',\n",
       " 'diciembre',\n",
       " 'diciendo',\n",
       " 'diera',\n",
       " 'dieron',\n",
       " 'diez',\n",
       " 'diferencia',\n",
       " 'diferente',\n",
       " 'diferentes',\n",
       " 'dificil',\n",
       " 'dificiles',\n",
       " 'diga',\n",
       " 'digo',\n",
       " 'dijo',\n",
       " 'dinamica',\n",
       " 'dinero',\n",
       " 'dio',\n",
       " 'dios',\n",
       " 'directamente',\n",
       " 'diria',\n",
       " 'discreta',\n",
       " 'discreto',\n",
       " 'dise',\n",
       " 'disenada',\n",
       " 'diseno',\n",
       " 'disenos',\n",
       " 'disponible',\n",
       " 'dispositivo',\n",
       " 'dispositivos',\n",
       " 'distintas',\n",
       " 'distintos',\n",
       " 'distraida',\n",
       " 'diu',\n",
       " 'divertida',\n",
       " 'divertido',\n",
       " 'do',\n",
       " 'doctor',\n",
       " 'dolares',\n",
       " 'dolor',\n",
       " 'dolores',\n",
       " 'dos',\n",
       " 'doy',\n",
       " 'duda',\n",
       " 'dudas',\n",
       " 'duele',\n",
       " 'dura',\n",
       " 'duracion',\n",
       " 'duro',\n",
       " 'echo',\n",
       " 'edad',\n",
       " 'editar',\n",
       " 'educativa',\n",
       " 'efectiva',\n",
       " 'efectivo',\n",
       " 'eficaz',\n",
       " 'eficiente',\n",
       " 'eh',\n",
       " 'ej',\n",
       " 'ejemplo',\n",
       " 'ejercicio',\n",
       " 'ejercicios',\n",
       " 'electronico',\n",
       " 'elegir',\n",
       " 'elementos',\n",
       " 'eliminar',\n",
       " 'elimine',\n",
       " 'ello',\n",
       " 'email',\n",
       " 'embaraza',\n",
       " 'embarazada',\n",
       " 'embarazadas',\n",
       " 'embarazados',\n",
       " 'embarazarme',\n",
       " 'embarazarte',\n",
       " 'embarazo',\n",
       " 'embarazos',\n",
       " 'embargo',\n",
       " 'emergencia',\n",
       " 'emocional',\n",
       " 'emocionales',\n",
       " 'emociones',\n",
       " 'empece',\n",
       " 'empezando',\n",
       " 'empezar',\n",
       " 'empezaron',\n",
       " 'empezo',\n",
       " 'empieza',\n",
       " 'empiezo',\n",
       " 'enamorada',\n",
       " 'encanta',\n",
       " 'encantaba',\n",
       " 'encantada',\n",
       " 'encantado',\n",
       " 'encantan',\n",
       " 'encantaria',\n",
       " 'encanto',\n",
       " 'encima',\n",
       " 'encontrado',\n",
       " 'encontrar',\n",
       " 'encontre',\n",
       " 'encuentra',\n",
       " 'encuentras',\n",
       " 'encuentro',\n",
       " 'encuestas',\n",
       " 'ende',\n",
       " 'energia',\n",
       " 'enero',\n",
       " 'enfermedades',\n",
       " 'enhorabuena',\n",
       " 'enseguida',\n",
       " 'ensena',\n",
       " 'enserio',\n",
       " 'entender',\n",
       " 'entendible',\n",
       " 'entiende',\n",
       " 'entiendo',\n",
       " 'entonces',\n",
       " 'entrar',\n",
       " 'entrega',\n",
       " 'entretenida',\n",
       " 'entro',\n",
       " 'envia',\n",
       " 'enviar',\n",
       " 'envie',\n",
       " 'equipo',\n",
       " 'equivoca',\n",
       " 'error',\n",
       " 'errores',\n",
       " 'escribir',\n",
       " 'escrito',\n",
       " 'esencial',\n",
       " 'espacio',\n",
       " 'espanol',\n",
       " 'especial',\n",
       " 'especialmente',\n",
       " 'especifica',\n",
       " 'especifico',\n",
       " 'espectacular',\n",
       " 'espera',\n",
       " 'esperaba',\n",
       " 'esperando',\n",
       " 'esperar',\n",
       " 'espero',\n",
       " 'esposa',\n",
       " 'esposo',\n",
       " 'esque',\n",
       " 'estadistica',\n",
       " 'estadisticas',\n",
       " 'estan',\n",
       " 'estaria',\n",
       " 'esten',\n",
       " 'estes',\n",
       " 'estetica',\n",
       " 'esteticamente',\n",
       " 'estilo',\n",
       " 'estrella',\n",
       " 'estrellas',\n",
       " 'estrellitas',\n",
       " 'estres',\n",
       " 'estupenda',\n",
       " 'estupendo',\n",
       " 'etapa',\n",
       " 'etapas',\n",
       " 'etc',\n",
       " 'evaluar',\n",
       " 'eventos',\n",
       " 'evitar',\n",
       " 'evolucion',\n",
       " 'exacta',\n",
       " 'exactamente',\n",
       " 'exactas',\n",
       " 'exactitud',\n",
       " 'exacto',\n",
       " 'exactos',\n",
       " 'excelente',\n",
       " 'excelentes',\n",
       " 'excepto',\n",
       " 'exelente',\n",
       " 'existe',\n",
       " 'existen',\n",
       " 'existir',\n",
       " 'exito',\n",
       " 'expectativas',\n",
       " 'experiencia',\n",
       " 'experiencias',\n",
       " 'explica',\n",
       " 'explicacion',\n",
       " 'explicaciones',\n",
       " 'explican',\n",
       " 'explicar',\n",
       " 'extra',\n",
       " 'extras',\n",
       " 'fabulosa',\n",
       " 'facebook',\n",
       " 'facil',\n",
       " 'facilidad',\n",
       " 'facilita',\n",
       " 'facilmente',\n",
       " 'factores',\n",
       " 'falla',\n",
       " 'fallado',\n",
       " 'fallando',\n",
       " 'fallar',\n",
       " 'fallas',\n",
       " 'fallo',\n",
       " 'fallos',\n",
       " 'falta',\n",
       " 'faltan',\n",
       " 'faltaria',\n",
       " 'familia',\n",
       " 'fantastica',\n",
       " 'fantastico',\n",
       " 'fascina',\n",
       " 'fascinada',\n",
       " 'fase',\n",
       " 'fases',\n",
       " 'fatal',\n",
       " 'favor',\n",
       " 'favorita',\n",
       " 'favoritas',\n",
       " 'fe',\n",
       " 'febrero',\n",
       " 'fecha',\n",
       " 'fechas',\n",
       " 'felicidades',\n",
       " 'felicitaciones',\n",
       " 'felicito',\n",
       " 'feliz',\n",
       " 'femenina',\n",
       " 'femenino',\n",
       " 'femeninos',\n",
       " 'fenomenal',\n",
       " 'fertil',\n",
       " 'fertiles',\n",
       " 'fertilidad',\n",
       " 'fiable',\n",
       " 'fin',\n",
       " 'final',\n",
       " 'fisica',\n",
       " 'fisico',\n",
       " 'fisicos',\n",
       " 'flores',\n",
       " 'flujo',\n",
       " 'fondo',\n",
       " 'fondos',\n",
       " 'forma',\n",
       " 'formas',\n",
       " 'formato',\n",
       " 'foro',\n",
       " 'foros',\n",
       " 'frecuencia',\n",
       " 'free',\n",
       " 'fuerte',\n",
       " 'full',\n",
       " 'funcion',\n",
       " 'funciona',\n",
       " 'funcionaba',\n",
       " 'funcionado',\n",
       " 'funcional',\n",
       " 'funcionalidad',\n",
       " 'funcionamiento',\n",
       " 'funcionan',\n",
       " 'funcionando',\n",
       " 'funcionar',\n",
       " 'funcione',\n",
       " 'funciones',\n",
       " 'funciono',\n",
       " 'futuro',\n",
       " 'futuros',\n",
       " 'galaxy',\n",
       " 'gana',\n",
       " 'ganar',\n",
       " 'ganas',\n",
       " 'genera',\n",
       " 'general',\n",
       " 'genero',\n",
       " 'genial',\n",
       " 'geniales',\n",
       " 'gente',\n",
       " 'gestacion',\n",
       " 'ginecologa',\n",
       " 'ginecologo',\n",
       " 'gmail',\n",
       " 'google',\n",
       " 'gracias',\n",
       " 'grafica',\n",
       " 'graficas',\n",
       " 'grafico',\n",
       " 'graficos',\n",
       " 'gran',\n",
       " 'grande',\n",
       " 'gratis',\n",
       " 'gratuita',\n",
       " 'gratuitas',\n",
       " 'gratuito',\n",
       " 'gratuitos',\n",
       " 'guarda',\n",
       " 'guardada',\n",
       " 'guardado',\n",
       " 'guardados',\n",
       " 'guardan',\n",
       " 'guardar',\n",
       " 'guarde',\n",
       " 'guardo',\n",
       " 'guia',\n",
       " 'gusta',\n",
       " 'gustaba',\n",
       " 'gustado',\n",
       " 'gustan',\n",
       " 'gustando',\n",
       " 'gustaria',\n",
       " 'gusto',\n",
       " 'habeis',\n",
       " 'haber',\n",
       " 'haberla',\n",
       " 'habia',\n",
       " 'habian',\n",
       " 'habitos',\n",
       " 'hablar',\n",
       " 'hace',\n",
       " 'hacen',\n",
       " 'hacer',\n",
       " 'hacerlo',\n",
       " 'hacerme',\n",
       " 'haces',\n",
       " 'haci',\n",
       " 'hacia',\n",
       " 'haciendo',\n",
       " 'haga',\n",
       " 'hagan',\n",
       " 'hago',\n",
       " 'haria',\n",
       " 'hecha',\n",
       " 'hecho',\n",
       " 'hermana',\n",
       " 'hermosa',\n",
       " 'hermoso',\n",
       " 'herramienta',\n",
       " 'herramientas',\n",
       " 'hice',\n",
       " 'hicieron',\n",
       " 'higiene',\n",
       " 'hija',\n",
       " 'hijo',\n",
       " 'hijos',\n",
       " 'hilos',\n",
       " 'historia',\n",
       " 'historial',\n",
       " 'historico',\n",
       " 'hizo',\n",
       " 'hola',\n",
       " 'hombre',\n",
       " 'hombres',\n",
       " 'hora',\n",
       " 'horario',\n",
       " 'horas',\n",
       " 'hormonal',\n",
       " 'hormonales',\n",
       " 'hormonas',\n",
       " 'horrible',\n",
       " 'hoy',\n",
       " 'huella',\n",
       " 'humor',\n",
       " 'iba',\n",
       " 'icono',\n",
       " 'iconos',\n",
       " 'idea',\n",
       " 'ideal',\n",
       " 'identificar',\n",
       " 'idioma',\n",
       " 'idiomas',\n",
       " 'ido',\n",
       " 'igual',\n",
       " 'imagen',\n",
       " 'implante',\n",
       " 'importa',\n",
       " 'importancia',\n",
       " 'importante',\n",
       " 'importantes',\n",
       " 'importar',\n",
       " 'imposible',\n",
       " 'imprescindible',\n",
       " 'incluir',\n",
       " 'incluso',\n",
       " 'incluye',\n",
       " 'incomodo',\n",
       " 'inconveniente',\n",
       " 'increible',\n",
       " 'increiblemente',\n",
       " 'increibles',\n",
       " 'indica',\n",
       " 'indicar',\n",
       " 'indispensable',\n",
       " 'infertiles',\n",
       " 'info',\n",
       " 'informa',\n",
       " 'informacion',\n",
       " 'informaciones',\n",
       " 'informada',\n",
       " 'informarme',\n",
       " 'informarte',\n",
       " 'informativa',\n",
       " 'informativo',\n",
       " 'informativos',\n",
       " 'informe',\n",
       " 'informes',\n",
       " 'ingles',\n",
       " 'ingresar',\n",
       " ...]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zero_tp = TopicModelDataPreparation(\"paraphrase-multilingual-mpnet-base-v2\")\n",
    "zero_training_dataset = zero_tp.fit(text_for_contextual=unpreprocessed_corpus, text_for_bow=preprocessed_documents) \n",
    "zero_tp.vocab "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "DataLoader worker (pid(s) 312, 12764, 9644, 14228, 10064, 10800, 10236, 12092) exited unexpectedly",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mEmpty\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    989\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 990\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_data_queue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    991\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\multiprocessing\\queues.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(self, block, timeout)\u001b[0m\n\u001b[0;32m    107\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 108\u001b[1;33m                         \u001b[1;32mraise\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    109\u001b[0m                 \u001b[1;32melif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mEmpty\u001b[0m: ",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-53efa450620b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m zero_ctm = ZeroShotTM(bow_size=len(zero_tp.vocab), contextual_size=768,\n\u001b[0;32m      6\u001b[0m                       n_components=topicnumber, num_epochs=50, batch_size = 33) # we get an error when batch size too high (DataLoader worker (pid(s))\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mzero_ctm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mzero_training_dataset\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#, n_samples=1)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mpickle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mzero_ctm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfolder\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mscriptfile\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mtopicnum\u001b[0m \u001b[1;33m+\u001b[0m\u001b[0mlanguage\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\"k_zero_ctm.pkl\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"wb\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\contextualized_topic_models\\models\\ctm.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, train_dataset, validation_dataset, save_dir, verbose, patience, delta, n_samples)\u001b[0m\n\u001b[0;32m    272\u001b[0m             \u001b[1;31m# train epoch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    273\u001b[0m             \u001b[0ms\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 274\u001b[1;33m             \u001b[0msp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_train_epoch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    275\u001b[0m             \u001b[0msamples_processed\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0msp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    276\u001b[0m             \u001b[0me\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\contextualized_topic_models\\models\\ctm.py\u001b[0m in \u001b[0;36m_train_epoch\u001b[1;34m(self, loader)\u001b[0m\n\u001b[0;32m    172\u001b[0m         \u001b[0msamples_processed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    173\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 174\u001b[1;33m         \u001b[1;32mfor\u001b[0m \u001b[0mbatch_samples\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mloader\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    175\u001b[0m             \u001b[1;31m# batch_size x vocab_size\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    176\u001b[0m             \u001b[0mX_bow\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch_samples\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'X_bow'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    519\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    520\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 521\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    522\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    523\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[1;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1184\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1185\u001b[0m             \u001b[1;32massert\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_shutdown\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1186\u001b[1;33m             \u001b[0midx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1187\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[1;33m-=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1188\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIterable\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m_get_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1150\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1151\u001b[0m             \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1152\u001b[1;33m                 \u001b[0msuccess\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_try_get_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1153\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1154\u001b[0m                     \u001b[1;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m   1001\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfailed_workers\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1002\u001b[0m                 \u001b[0mpids_str\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m', '\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpid\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mfailed_workers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1003\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'DataLoader worker (pid(s) {}) exited unexpectedly'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpids_str\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1004\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mqueue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mEmpty\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1005\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: DataLoader worker (pid(s) 312, 12764, 9644, 14228, 10064, 10800, 10236, 12092) exited unexpectedly"
     ]
    }
   ],
   "source": [
    "## Run the model - here is where the problem is\n",
    "scriptfile = '0301_'\n",
    "folder = '03_data/02_output/01_spanish/'\n",
    "topicnum = '33'\n",
    "topicnumber = 33\n",
    "zero_ctm = ZeroShotTM(bow_size=len(zero_tp.vocab), contextual_size=768,\n",
    "                      n_components=topicnumber, num_epochs=50, batch_size = 33) # we get an error I think maybe related to batch size (DataLoader worker (pid(s)) - but we get this problem even when batch_size = 1\n",
    "zero_ctm.fit(zero_training_dataset) #, n_samples=1) \n",
    "\n",
    "pickle.dump(zero_ctm, open(folder + scriptfile + topicnum +language + \"k_zero_ctm.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Spanish topic prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spanish_topics_predictions = zero_ctm.training_doc_topic_distributions\n",
    "scriptfile = '0301_'\n",
    "folder = '03_data/02_output/01_spanish/'\n",
    "pickle.dump(spanish_topics_predictions, open(folder + scriptfile + topicnum + language +\"spanish_topics_predictions.pkl\", \"wb\")) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Non-Spanish topic prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zero_tp = TopicModelDataPreparation(\"paraphrase-multilingual-mpnet-base-v2\")\n",
    "testing_dataset = zero_tp.transform(test_docs)\n",
    "\n",
    "nonspanish_topics_predictions = zero_ctm.get_thetas(testing_dataset, n_samples=1) \n",
    "\n",
    "pickle.dump(nonspanish_topics_predictions, open(folder + scriptfile  + topicnum + \"nonspanish_topics_predictions.pkl\", \"wb\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0202 - import/export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "cwd = os.getcwd()\n",
    "print('Current Standard Directory is: ', cwd)\n",
    "absolute_path = 'C:/Users/rbarker/OneDrive/02_Fertapp' \n",
    "os.chdir(absolute_path)\n",
    "print('New working directory is: ', os.getcwd())\n",
    "\n",
    "sourcescriptfile = \"0301_\"\n",
    "folder = '03_data/02_output/01_spanish/'\n",
    "topicnum = '33'\n",
    "language = 'spanish_'\n",
    "zero_ctm = pickle.load(open(folder + sourcescriptfile + topicnum +language + \"k_zero_ctm.pkl\", \"rb\"))\n",
    "nonspanish_topics_predictions = pickle.load(open(folder + sourcescriptfile + topicnum + \"nonspanish_topics_predictions.pkl\", \"rb\"))\n",
    "spanish_topics_predictions = pickle.load(open(folder + sourcescriptfile +  topicnum +language + \"spanish_topics_predictions.pkl\", \"rb\"))\n",
    "mytopic_lists = zero_ctm.get_topic_lists(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Exporing the matrices\n",
    "import pandas as pd\n",
    "scriptfile = \"0301_\"\n",
    "topicnum = '33'\n",
    "typeofsource = 'reviews'\n",
    "\n",
    "## to DF\n",
    "nonspanish_topics_predictions = pd.DataFrame(nonspanish_topics_predictions)\n",
    "spanish_topics_predictions = pd.DataFrame(spanish_topics_predictions)\n",
    "mytopic_lists = pd.DataFrame(mytopic_lists)\n",
    "\n",
    "# export\n",
    "nonspanish_topics_predictions.to_csv(folder + scriptfile + topicnum + typeofsource + \"nonspanish_topics_predictions.csv\",index=False)\n",
    "spanish_topics_predictions.to_csv(folder + scriptfile + topicnum + typeofsource +language + \"spanish_topics_predictions.csv\",index=False)\n",
    "mytopic_lists.to_csv(folder + scriptfile + topicnum + typeofsource +language +  \"mytopic_lists.csv\",index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sourcescriptfile = '0300_'\n",
    "spanishsample = pickle.load(open(folder + sourcescriptfile + \"spanishsample.pkl\", \"rb\"))\n",
    "nonspanishsample = pickle.load(open(folder + sourcescriptfile + \"nonspanishsample.pkl\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### adding a uniique identifier\n",
    "spanishsample[\"comparableid\"] = spanishsample.index # getting my row index\n",
    "spanishsample = spanishsample.applymap(str)\n",
    "spanishsample['newcomparableid'] = spanishsample.comparableid + spanishsample.id + spanishsample.language\n",
    "\n",
    "nonspanishsample[\"comparableid\"] = nonspanishsample.index # getting my row index\n",
    "nonspanishsample = nonspanishsample.applymap(str)\n",
    "nonspanishsample['newcomparableid'] = nonspanishsample.comparableid + nonspanishsample.id + nonspanishsample.language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spanishsample = pd.DataFrame(spanishsample)\n",
    "spanishsample['row_num'] = spanishsample.reset_index().index\n",
    "spanish_topics_predictions = pd.DataFrame(spanish_topics_predictions)\n",
    "spanish_topics_predictions['row_num'] = spanish_topics_predictions.reset_index().index\n",
    "spanish = spanishsample.merge(spanish_topics_predictions, on='row_num')\n",
    "\n",
    "\n",
    "nonspanishsample = pd.DataFrame(nonspanishsample)\n",
    "nonspanishsample['row_num'] = nonspanishsample.reset_index(drop=True).index\n",
    "nonspanish_topics_predictions = pd.DataFrame(nonspanish_topics_predictions)\n",
    "nonspanish_topics_predictions['row_num'] = nonspanish_topics_predictions.reset_index().index\n",
    "nonspanish = nonspanishsample.merge(nonspanish_topics_predictions, on='row_num')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### here, we export \n",
    "scriptfile = \"0302_\"\n",
    "folder = '03_data/02_output/01_spanish/'\n",
    "topicnum = '33'\n",
    "typeofsource = 'reviews'\n",
    "spanish.to_csv(folder + scriptfile + topicnum + typeofsource + \"spanish.csv\",index=False)\n",
    "nonspanish.to_csv(folder + scriptfile + topicnum + typeofsource + \"nonspanish.csv\",index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
